{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 01 - Predict Price of Diamonds\n",
    "This is the first assignment of the UNICAMP lecture MO444-Machine Learning and Pattern Recognition\n",
    "\n",
    "## Objective\n",
    "Explore linear  regression alternatives  and  come  up  with  the  best  possible  model  to  the  problems,  avoiding overfitting. In particular, predict the price of diamonds from their attributes (e.g., depth, clarity, color) using the Diamonds dataset (https://www.kaggle.com/shivam2503/diamonds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Diamonds Dataset and Visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_and_validation_dataset = pd.read_csv('diamonds-dataset/diamonds-train.csv')\n",
    "test_dataset = pd.read_csv('diamonds-dataset/diamonds-train.csv')\n",
    "#train_and_validation_dataset.head()\n",
    "#test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split original \"train\" dataset onto 80% train and 20% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset = train_test_split(train_and_validation_dataset, train_size=0.8, test_size=0.2)\n",
    "#train_dataset.head()\n",
    "#alidation_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Dataset \n",
    "Transform properties \"cut\", \"color\" and \"clarity\" into usable features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocessDataset(dataset):\n",
    "    dataset = dataset.copy() # avoid false positive of \"A value is trying to be set on a copy of a slice from a DataFrame\"\n",
    "    dataset.cut.replace('Fair', 0, inplace=True)\n",
    "    dataset.cut.replace('Good', 1, inplace=True)\n",
    "    dataset.cut.replace('Very Good', 2, inplace=True)\n",
    "    dataset.cut.replace('Premium', 3, inplace=True)\n",
    "    dataset.cut.replace('Ideal', 4, inplace=True)\n",
    "\n",
    "    dataset.color.replace('D', 6, inplace=True)\n",
    "    dataset.color.replace('E', 5, inplace=True)\n",
    "    dataset.color.replace('F', 4, inplace=True)\n",
    "    dataset.color.replace('G', 3, inplace=True)\n",
    "    dataset.color.replace('H', 2, inplace=True)\n",
    "    dataset.color.replace('I', 1, inplace=True)\n",
    "    dataset.color.replace('J', 0, inplace=True)\n",
    "\n",
    "    dataset.clarity.replace('I1', 0, inplace=True)\n",
    "    dataset.clarity.replace('SI2', 1, inplace=True)\n",
    "    dataset.clarity.replace('SI1', 2, inplace=True)\n",
    "    dataset.clarity.replace('VS2', 3, inplace=True)\n",
    "    dataset.clarity.replace('VS1', 4, inplace=True)\n",
    "    dataset.clarity.replace('VVS2', 5, inplace=True)\n",
    "    dataset.clarity.replace('VVS1', 6, inplace=True)\n",
    "    dataset.clarity.replace('IF', 7, inplace=True)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "preprocessed_train_dataset = preprocessDataset(train_dataset)\n",
    "preprocessed_validation_dataset = preprocessDataset(validation_dataset)\n",
    "#preprocessed_train_dataset.head()\n",
    "#preprocessed_validation_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Dataset\n",
    "- Scale dataset based on the training part\n",
    "- Scale the validation dataset using the same scale factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(preprocessed_train_dataset)\n",
    "scaled_train_dataset = pd.DataFrame(scaler.transform(preprocessed_train_dataset), columns=preprocessed_train_dataset.columns)\n",
    "scaled_validation_dataset = pd.DataFrame(scaler.transform(preprocessed_validation_dataset), columns=preprocessed_validation_dataset.columns)\n",
    "#scaled_train_dataset.head()\n",
    "#scaled_validation_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Linear Model\n",
    "- Divide datasets into inputs and output\n",
    "- Create a linear regression model \n",
    "- Fit it to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaled_train_dataset.drop(columns=['price'])\n",
    "Y_train =  scaled_train_dataset['price']\n",
    "X_val = scaled_validation_dataset.drop(columns=['price'])\n",
    "Y_val = scaled_validation_dataset['price']\n",
    "\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg = lin_reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict using the Model\n",
    "- Predict using the scaled validation input\n",
    "- Analyse the accuracy of the prediction\n",
    "- Apply the inverse scaler to the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9092383857867203"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predicted_scaled = lin_reg.predict(X_val)\n",
    "Score = lin_reg.score(X_val, Y_val)\n",
    "Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze accuracy of the model\n",
    "- plot?\n",
    "- Cost function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
